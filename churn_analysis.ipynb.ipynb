{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "251032e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "1) LOADING DATA & BASIC CHECKS\n",
      "============================================================\n",
      "Loaded dataset with shape: (7043, 21)\n",
      "\n",
      "Class distribution (normalized):\n",
      "{'No': 0.7346301292063041, 'Yes': 0.2653698707936959}\n",
      "Imbalance ratio: 2.77:1\n",
      "⚠️  Class imbalance detected — SMOTETomek will be used on training set.\n",
      "\n",
      "============================================================\n",
      "2) FEATURE ENGINEERING — focused & interpretable\n",
      "============================================================\n",
      "Kept 15 handcrafted features for modeling.\n",
      "\n",
      "============================================================\n",
      "3) ENCODE & SPLIT\n",
      "============================================================\n",
      "Train shape: (5634, 15) | Test shape: (1409, 15)\n",
      "\n",
      "============================================================\n",
      "4) APPLY SMOTETOMEK (TRAINING SET ONLY)\n",
      "============================================================\n",
      "After resampling, training class distribution: {0: 3843, 1: 3843}\n",
      "\n",
      "============================================================\n",
      "5) FEATURE SELECTION (SelectKBest)\n",
      "============================================================\n",
      "Selected top 15 features.\n",
      "Top features: ['AvgMonthlyCharges', 'MonthlyCharges', 'TotalCharges', 'tenure', 'IsNewCustomer', 'IsLoyalCustomer', 'IsMonthToMonth', 'ContractValue', 'TotalServices', 'IsElectronicPayment']\n",
      "\n",
      "============================================================\n",
      "6) SCALE FEATURES (RobustScaler)\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "7) TRAINING — 3 MODELS + SOFT VOTING\n",
      "============================================================\n",
      "\n",
      "Training LogisticRegression ...\n",
      "  CV ROC AUC mean: 0.8909 (+/- 0.0035)\n",
      "  Test AUC: 0.8307 | F1: 0.6137\n",
      "\n",
      "Training RandomForest ...\n",
      "  CV ROC AUC mean: 0.9211 (+/- 0.0014)\n",
      "  Test AUC: 0.8283 | F1: 0.6205\n",
      "\n",
      "Training GradientBoosting ...\n",
      "  CV ROC AUC mean: 0.9187 (+/- 0.0020)\n",
      "  Test AUC: 0.8352 | F1: 0.6214\n",
      "\n",
      "Voting ensemble results:\n",
      "  AUC: 0.8388 | F1: 0.6219\n",
      "\\Best model by AUC: VotingEnsemble\n",
      "\n",
      "============================================================\n",
      "8) EVALUATION & BUSINESS INSIGHTS\n",
      "============================================================\n",
      "\n",
      "Confusion Matrix:\n",
      "[[804 231]\n",
      " [101 273]]\n",
      "Sensitivity (Recall): 0.7299\n",
      "Specificity: 0.7768\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       0.89      0.78      0.83      1035\n",
      "       Churn       0.54      0.73      0.62       374\n",
      "\n",
      "    accuracy                           0.76      1409\n",
      "   macro avg       0.72      0.75      0.73      1409\n",
      "weighted avg       0.80      0.76      0.77      1409\n",
      "\n",
      "\n",
      "Model summary (selected model):\n",
      "  Accuracy: 0.7644\n",
      "  Precision: 0.5417\n",
      "  Recall: 0.7299\n",
      "  F1: 0.6219\n",
      "  ROC AUC: 0.8388\n",
      "\n",
      " BUSINESS INSIGHTS (human-friendly):\n",
      "- Month-to-month contract customers are highest risk — target them with offers.\n",
      "- New customers (<12 months) with high monthly charges churn faster.\n",
      "- Customers with more services and higher engagement scores show lower churn risk.\n",
      "- Electronic-check payments correlate with higher churn probability (payment friction).\n",
      "\n",
      "============================================================\n",
      "9) SAVE ARTIFACTS & EXPORT PREDICTIONS\n",
      "============================================================\n",
      "Saved model and artifacts to output_handcrafted/\n",
      "Exported predictions to output_handcrafted\\churn_predictions.csv\n",
      "\n",
      " Pipeline finished. Check output_handcrafted/ for artifacts and churn_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Handcrafted Churn Predictor — Clean, Explainable, Effective\n",
    "- Focus: meaningful features, interpretability, good accuracy\n",
    "- Models: LogisticRegression, RandomForest, GradientBoosting + soft Voting\n",
    "- Feature selection: SelectKBest (top 20)\n",
    "- Optional imbalance handling (SMOTE) only if needed\n",
    "- Outputs: saved model components + churn_predictions.csv + short business insights\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, RobustScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             roc_auc_score, confusion_matrix, classification_report)\n",
    "\n",
    "# Optional: for imbalance handling if class imbalance detected\n",
    "try:\n",
    "    from imblearn.combine import SMOTETomek\n",
    "    IMBL_AVAILABLE = True\n",
    "except Exception:\n",
    "    IMBL_AVAILABLE = False\n",
    "\n",
    "\n",
    "class HandcraftedChurnPredictor:\n",
    "    \"\"\"\n",
    "    A compact, purposeful churn pipeline:\n",
    "      - clean + small set of explainable features\n",
    "      - encode, split, optional SMOTE\n",
    "      - SelectKBest (top 20)\n",
    "      - scale, train three models + voting ensemble\n",
    "      - evaluate, save, export actionable predictions\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, k_best: int = 20, random_state: int = 42):\n",
    "        self.data_path = data_path\n",
    "        self.random_state = random_state\n",
    "        self.k_best = k_best\n",
    "        self.df = None\n",
    "        self.label_encoders = {}\n",
    "        self.scaler = RobustScaler()\n",
    "        self.feature_selector = None\n",
    "        self.selected_features: List[str] = []\n",
    "        self.best_model = None\n",
    "        self.results = {}\n",
    "        \n",
    "\n",
    "    # ------------------------\n",
    "    # 1. Load & basic checks\n",
    "    # ------------------------\n",
    "    def load_data(self):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"1) LOADING DATA & BASIC CHECKS\")\n",
    "        print(\"=\" * 60)\n",
    "        self.df = pd.read_csv(self.data_path)\n",
    "        print(f\"Loaded dataset with shape: {self.df.shape}\")\n",
    "\n",
    "\n",
    "        # check churn column presence\n",
    "        if 'Churn' not in self.df.columns:\n",
    "            raise ValueError(\"Dataset must contain a 'Churn' column.\")\n",
    "\n",
    "        # simple class balance check\n",
    "        churn_dist = self.df['Churn'].value_counts(normalize=True)\n",
    "        print(\"\\nClass distribution (normalized):\")\n",
    "        print(churn_dist.to_dict())\n",
    "        imbalance_ratio = churn_dist.max() / churn_dist.min()\n",
    "        print(f\"Imbalance ratio: {imbalance_ratio:.2f}:1\")\n",
    "\n",
    "        # decide whether to attempt imbalance handling\n",
    "        self.apply_smote = imbalance_ratio > 1.5 and IMBL_AVAILABLE\n",
    "        if imbalance_ratio > 1.5 and not IMBL_AVAILABLE:\n",
    "            print(\"Imbalance detected but imblearn not available — skipping SMOTE.\")\n",
    "            self.apply_smote = False\n",
    "        elif self.apply_smote:\n",
    "            print(\"⚠️  Class imbalance detected — SMOTETomek will be used on training set.\")\n",
    "        else:\n",
    "            print(\"Class balance acceptable — proceeding without SMOTE.\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    # ------------------------\n",
    "    # 2. Feature engineering (human-focused)\n",
    "    # ------------------------\n",
    "    def feature_engineering(self):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"2) FEATURE ENGINEERING — focused & interpretable\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        df = self.df.copy()\n",
    "\n",
    "        # keep original customer id if present for export\n",
    "        self.customer_id_col = None\n",
    "        for cid in ['customerID', 'customerId', 'CustomerID']:\n",
    "            if cid in df.columns:\n",
    "                self.customer_id_col = cid\n",
    "                break\n",
    "\n",
    "        # convert numeric-ish columns\n",
    "        if 'TotalCharges' in df.columns:\n",
    "            df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "\n",
    "        # fill sensible missing TotalCharges using MonthlyCharges * tenure\n",
    "        if set(['TotalCharges', 'MonthlyCharges', 'tenure']).issubset(df.columns):\n",
    "            df['TotalCharges'] = df['TotalCharges'].fillna(df['MonthlyCharges'] * df['tenure'])\n",
    "\n",
    "        # core handcrafted features — each should be explainable to a manager\n",
    "        # we'll create only a tight set (approx 10-12) to keep the model clean\n",
    "        # check presence of columns before using them (robustness)\n",
    "        def col_exists(c): return c in df.columns\n",
    "\n",
    "        # Avg monthly charge (proxy for value)\n",
    "        if col_exists('TotalCharges') and col_exists('tenure'):\n",
    "            df['AvgMonthlyCharges'] = df['TotalCharges'] / (df['tenure'] + 1)\n",
    "        elif col_exists('MonthlyCharges'):\n",
    "            df['AvgMonthlyCharges'] = df['MonthlyCharges']\n",
    "\n",
    "        # Is new customer\n",
    "        if col_exists('tenure'):\n",
    "            df['IsNewCustomer'] = (df['tenure'] <= 12).astype(int)\n",
    "            df['IsLoyalCustomer'] = (df['tenure'] > 36).astype(int)\n",
    "        else:\n",
    "            df['IsNewCustomer'] = 0\n",
    "            df['IsLoyalCustomer'] = 0\n",
    "\n",
    "        # Contract risk\n",
    "        if col_exists('Contract'):\n",
    "            df['IsMonthToMonth'] = (df['Contract'] == 'Month-to-month').astype(int)\n",
    "            contract_value = {'Month-to-month': 1, 'One year': 12, 'Two year': 24}\n",
    "            df['ContractValue'] = df['Contract'].map(contract_value).fillna(1)\n",
    "        else:\n",
    "            df['IsMonthToMonth'] = 0\n",
    "            df['ContractValue'] = 1\n",
    "\n",
    "        # Services count (robust count of key services)\n",
    "        service_cols = [c for c in ['PhoneService', 'MultipleLines', 'InternetService',\n",
    "                                    'OnlineSecurity', 'OnlineBackup', 'DeviceProtection',\n",
    "                                    'TechSupport', 'StreamingTV', 'StreamingMovies'] if c in df.columns]\n",
    "        if service_cols:\n",
    "            # treat 'No' or similar as not having\n",
    "            df['TotalServices'] = 0\n",
    "            for c in service_cols:\n",
    "                df['TotalServices'] += (~df[c].isin(['No', 'No phone service', 'No internet service', 'None'])).astype(int)\n",
    "        else:\n",
    "            df['TotalServices'] = 0\n",
    "\n",
    "        # Electronic payment risk\n",
    "        if col_exists('PaymentMethod'):\n",
    "            df['IsElectronicPayment'] = (df['PaymentMethod'] == 'Electronic check').astype(int)\n",
    "        else:\n",
    "            df['IsElectronicPayment'] = 0\n",
    "\n",
    "        # Paperless billing flag\n",
    "        if col_exists('PaperlessBilling'):\n",
    "            df['PaperlessBillingFlag'] = (df['PaperlessBilling'] == 'Yes').astype(int)\n",
    "        else:\n",
    "            df['PaperlessBillingFlag'] = 0\n",
    "\n",
    "        # High charge & new customer: potential early churn cause\n",
    "        if col_exists('MonthlyCharges') and col_exists('tenure'):\n",
    "            median_monthly = df['MonthlyCharges'].median()\n",
    "            df['HighChargeNewCustomer'] = ((df['MonthlyCharges'] > median_monthly) & (df['tenure'] < 12)).astype(int)\n",
    "        else:\n",
    "            df['HighChargeNewCustomer'] = 0\n",
    "\n",
    "        # Senior alone (simple demographic risk signal)\n",
    "        if set(['SeniorCitizen', 'Partner', 'Dependents']).issubset(df.columns):\n",
    "            df['SeniorAlone'] = ((df['SeniorCitizen'] == 1) & (df['Partner'] == 'No') & (df['Dependents'] == 'No')).astype(int)\n",
    "        else:\n",
    "            df['SeniorAlone'] = 0\n",
    "\n",
    "        # Engagement score (services * log(tenure + 1))\n",
    "        if col_exists('tenure'):\n",
    "            df['EngagementScore'] = df['TotalServices'] * np.log1p(df['tenure'])\n",
    "        else:\n",
    "            df['EngagementScore'] = df['TotalServices']\n",
    "\n",
    "        # Composite risk score (simple interpretable linear sum)\n",
    "        df['CompositeRiskScore'] = (\n",
    "            df['IsMonthToMonth'] * 3 +\n",
    "            df['IsNewCustomer'] * 2 +\n",
    "            df['IsElectronicPayment'] * 1 +\n",
    "            df['SeniorAlone'] * 2 +\n",
    "            df['HighChargeNewCustomer'] * 1\n",
    "        )\n",
    "\n",
    "        # Keep a curated list of feature candidates only (explainable ones)\n",
    "        candidate_features = []\n",
    "        for col in ['AvgMonthlyCharges', 'MonthlyCharges', 'TotalCharges', 'tenure',\n",
    "                    'IsNewCustomer', 'IsLoyalCustomer', 'IsMonthToMonth', 'ContractValue',\n",
    "                    'TotalServices', 'IsElectronicPayment', 'PaperlessBillingFlag',\n",
    "                    'HighChargeNewCustomer', 'SeniorAlone', 'EngagementScore', 'CompositeRiskScore']:\n",
    "            if col in df.columns:\n",
    "                candidate_features.append(col)\n",
    "\n",
    "        # Fill any remaining missing values with medians or zeros (simple, human)\n",
    "        for col in candidate_features:\n",
    "            if df[col].isnull().any():\n",
    "                if df[col].dtype.kind in \"biufc\":\n",
    "                    df[col] = df[col].fillna(df[col].median())\n",
    "                else:\n",
    "                    df[col] = df[col].fillna(0)\n",
    "\n",
    "        # reduce df to candidate features + target + id (keep other columns dropped to avoid accidental leakage)\n",
    "        columns_to_keep = candidate_features + ['Churn']\n",
    "        if self.customer_id_col:\n",
    "            columns_to_keep = [self.customer_id_col] + columns_to_keep\n",
    "\n",
    "        self.df = df.loc[:, [c for c in columns_to_keep if c in df.columns]].copy()\n",
    "\n",
    "        print(f\"Kept {len(candidate_features)} handcrafted features for modeling.\")\n",
    "        self.candidate_features = candidate_features\n",
    "        return self\n",
    "\n",
    "    # ------------------------\n",
    "    # 3. Encode, split\n",
    "    # ------------------------\n",
    "    def encode_and_split(self, test_size=0.2):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"3) ENCODE & SPLIT\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        df = self.df.copy()\n",
    "\n",
    "        # Encode any remaining object columns (should be minimal)\n",
    "        object_cols = df.select_dtypes(include='object').columns.tolist()\n",
    "        object_cols = [c for c in object_cols if c != 'Churn' and (self.customer_id_col is None or c != self.customer_id_col)]\n",
    "        for col in object_cols:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "            self.label_encoders[col] = le\n",
    "\n",
    "        # Encode target\n",
    "        le_target = LabelEncoder()\n",
    "        df['Churn'] = le_target.fit_transform(df['Churn'])\n",
    "        self.label_encoders['Churn'] = le_target\n",
    "\n",
    "        # Split\n",
    "        X = df.drop(columns=['Churn'] + ([self.customer_id_col] if self.customer_id_col else []))\n",
    "        y = df['Churn']\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            X, y, test_size=test_size, stratify=y, random_state=self.random_state\n",
    "        )\n",
    "\n",
    "        print(f\"Train shape: {self.X_train.shape} | Test shape: {self.X_test.shape}\")\n",
    "        return self\n",
    "\n",
    "    # ------------------------\n",
    "    # 4. Optional imbalance handling\n",
    "    # ------------------------\n",
    "    def handle_class_imbalance(self):\n",
    "        if not getattr(self, \"apply_smote\", False):\n",
    "            print(\"\\n  Skipping imbalance handling (not needed or not available).\")\n",
    "            return self\n",
    "\n",
    "        if not IMBL_AVAILABLE:\n",
    "            print(\"\\n imblearn not available — skipping SMOTE.\")\n",
    "            return self\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"4) APPLY SMOTETOMEK (TRAINING SET ONLY)\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        smote_tomek = SMOTETomek(random_state=self.random_state)\n",
    "        X_res, y_res = smote_tomek.fit_resample(self.X_train, self.y_train)\n",
    "        self.X_train, self.y_train = X_res, y_res\n",
    "        print(\"After resampling, training class distribution:\", pd.Series(self.y_train).value_counts().to_dict())\n",
    "        return self\n",
    "\n",
    "    # ------------------------\n",
    "    # 5. Feature selection (SelectKBest)\n",
    "    # ------------------------\n",
    "    def feature_selection(self):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"5) FEATURE SELECTION (SelectKBest)\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        n_features = min(self.k_best, self.X_train.shape[1])\n",
    "        selector = SelectKBest(score_func=f_classif, k=n_features)\n",
    "        X_train_sel = selector.fit_transform(self.X_train, self.y_train)\n",
    "        X_test_sel = selector.transform(self.X_test)\n",
    "\n",
    "        # get selected column names\n",
    "        selected_idx = selector.get_support(indices=True)\n",
    "        self.selected_features = self.X_train.columns[selected_idx].tolist()\n",
    "        self.feature_selector = selector\n",
    "\n",
    "        # update train/test to selected features\n",
    "        self.X_train = pd.DataFrame(X_train_sel, columns=self.selected_features, index=self.X_train.index)\n",
    "        self.X_test = pd.DataFrame(X_test_sel, columns=self.selected_features, index=self.X_test.index)\n",
    "\n",
    "        print(f\"Selected top {len(self.selected_features)} features.\")\n",
    "        print(\"Top features:\", self.selected_features[:10])\n",
    "        return self\n",
    "\n",
    "    # ------------------------\n",
    "    # 6. Scale\n",
    "    # ------------------------\n",
    "    def scale_features(self):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"6) SCALE FEATURES (RobustScaler)\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        self.X_train_scaled = self.scaler.fit_transform(self.X_train)\n",
    "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
    "        return self\n",
    "\n",
    "    # ------------------------\n",
    "    # 7. Train core models + voting\n",
    "    # ------------------------\n",
    "    def train_and_ensemble(self):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"7) TRAINING — 3 MODELS + SOFT VOTING\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        # simple, explainable models\n",
    "        lr = LogisticRegression(max_iter=1000, C=1.0, random_state=self.random_state)\n",
    "        rf = RandomForestClassifier(n_estimators=200, max_depth=12, n_jobs=-1, random_state=self.random_state)\n",
    "        gb = GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, max_depth=5, random_state=self.random_state)\n",
    "\n",
    "        # cross-validate each model (roc_auc)\n",
    "        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=self.random_state)\n",
    "        models = {'LogisticRegression': lr, 'RandomForest': rf, 'GradientBoosting': gb}\n",
    "\n",
    "        trained = {}\n",
    "        results = {}\n",
    "        for name, model in models.items():\n",
    "            print(f\"\\nTraining {name} ...\")\n",
    "            try:\n",
    "                cv_scores = cross_val_score(model, self.X_train_scaled, self.y_train, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "                print(f\"  CV ROC AUC mean: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "            except Exception:\n",
    "                print(\"  CV failed or skipped for speed.\")\n",
    "            model.fit(self.X_train_scaled, self.y_train)\n",
    "            y_pred = model.predict(self.X_test_scaled)\n",
    "            y_proba = model.predict_proba(self.X_test_scaled)[:, 1] if hasattr(model, \"predict_proba\") else model.decision_function(self.X_test_scaled)\n",
    "            results[name] = {\n",
    "                'accuracy': accuracy_score(self.y_test, y_pred),\n",
    "                'precision': precision_score(self.y_test, y_pred, zero_division=0),\n",
    "                'recall': recall_score(self.y_test, y_pred, zero_division=0),\n",
    "                'f1': f1_score(self.y_test, y_pred, zero_division=0),\n",
    "                'auc': roc_auc_score(self.y_test, y_proba)\n",
    "            }\n",
    "            trained[name] = model\n",
    "            print(f\"  Test AUC: {results[name]['auc']:.4f} | F1: {results[name]['f1']:.4f}\")\n",
    "\n",
    "        # Voting ensemble (soft)\n",
    "        voting = VotingClassifier(\n",
    "            estimators=[('lr', trained['LogisticRegression']), ('rf', trained['RandomForest']), ('gb', trained['GradientBoosting'])],\n",
    "            voting='soft', n_jobs=-1\n",
    "        )\n",
    "        voting.fit(self.X_train_scaled, self.y_train)\n",
    "        y_pred_vote = voting.predict(self.X_test_scaled)\n",
    "        y_proba_vote = voting.predict_proba(self.X_test_scaled)[:, 1]\n",
    "        results['VotingEnsemble'] = {\n",
    "            'accuracy': accuracy_score(self.y_test, y_pred_vote),\n",
    "            'precision': precision_score(self.y_test, y_pred_vote, zero_division=0),\n",
    "            'recall': recall_score(self.y_test, y_pred_vote, zero_division=0),\n",
    "            'f1': f1_score(self.y_test, y_pred_vote, zero_division=0),\n",
    "            'auc': roc_auc_score(self.y_test, y_proba_vote)\n",
    "        }\n",
    "        print(\"\\nVoting ensemble results:\")\n",
    "        print(f\"  AUC: {results['VotingEnsemble']['auc']:.4f} | F1: {results['VotingEnsemble']['f1']:.4f}\")\n",
    "\n",
    "        # pick best by AUC\n",
    "        best_name = max(results, key=lambda k: results[k]['auc'])\n",
    "        print(f\"\\Best model by AUC: {best_name}\")\n",
    "        self.results = results\n",
    "        self.best_model = voting if best_name == 'VotingEnsemble' else trained[best_name]\n",
    "        self.all_models = trained\n",
    "        self.model_name = best_name\n",
    "        return self\n",
    "\n",
    "    # ------------------------\n",
    "    # 8. Evaluate + Insights\n",
    "    # ------------------------\n",
    "    def evaluate_and_report(self):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"8) EVALUATION & BUSINESS INSIGHTS\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        model = self.best_model\n",
    "        y_pred = model.predict(self.X_test_scaled)\n",
    "        y_proba = model.predict_proba(self.X_test_scaled)[:, 1]\n",
    "\n",
    "        # confusion matrix and derived metrics\n",
    "        cm = confusion_matrix(self.y_test, y_pred)\n",
    "        tn, fp, fn, tp = cm.ravel()\n",
    "        specificity = tn / (tn + fp) if (tn + fp) else 0\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) else 0\n",
    "\n",
    "        print(f\"\\nConfusion Matrix:\\n{cm}\")\n",
    "        print(f\"Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "        print(f\"Specificity: {specificity:.4f}\")\n",
    "\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(self.y_test, y_pred, target_names=['No Churn', 'Churn']))\n",
    "\n",
    "        # print compact metrics summary\n",
    "        best_res = self.results.get(self.model_name, {})\n",
    "        print(\"\\nModel summary (selected model):\")\n",
    "        print(f\"  Accuracy: {best_res.get('accuracy', 0):.4f}\")\n",
    "        print(f\"  Precision: {best_res.get('precision', 0):.4f}\")\n",
    "        print(f\"  Recall: {best_res.get('recall', 0):.4f}\")\n",
    "        print(f\"  F1: {best_res.get('f1', 0):.4f}\")\n",
    "        print(f\"  ROC AUC: {best_res.get('auc', 0):.4f}\")\n",
    "\n",
    "        # Simple human-readable insights (based on feature effects we engineered)\n",
    "        print(\"\\n BUSINESS INSIGHTS (human-friendly):\")\n",
    "        print(\"- Month-to-month contract customers are highest risk — target them with offers.\")\n",
    "        print(\"- New customers (<12 months) with high monthly charges churn faster.\")\n",
    "        print(\"- Customers with more services and higher engagement scores show lower churn risk.\")\n",
    "        print(\"- Electronic-check payments correlate with higher churn probability (payment friction).\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    # ------------------------\n",
    "    # 9. Save artifacts + export predictions CSV\n",
    "    # ------------------------\n",
    "    def save_artifacts_and_export(self, out_dir=\"output\"):\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"9) SAVE ARTIFACTS & EXPORT PREDICTIONS\")\n",
    "        print(\"=\" * 60)\n",
    "\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "        # save model + scaler + encoders + feature selector + selected features\n",
    "        with open(os.path.join(out_dir, \"model.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.best_model, f)\n",
    "        with open(os.path.join(out_dir, \"scaler.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.scaler, f)\n",
    "        with open(os.path.join(out_dir, \"encoders.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.label_encoders, f)\n",
    "        with open(os.path.join(out_dir, \"feature_selector.pkl\"), \"wb\") as f:\n",
    "            pickle.dump(self.feature_selector, f)\n",
    "        with open(os.path.join(out_dir, \"selected_features.txt\"), \"w\") as f:\n",
    "            for feat in self.selected_features:\n",
    "                f.write(feat + \"\\n\")\n",
    "\n",
    "        print(f\"Saved model and artifacts to {out_dir}/\")\n",
    "\n",
    "        # export test predictions with probabilities and customer IDs if present\n",
    "        X_test_df = self.X_test.copy()\n",
    "        preds = self.best_model.predict(self.X_test_scaled)\n",
    "        probs = self.best_model.predict_proba(self.X_test_scaled)[:, 1]\n",
    "\n",
    "        export_df = pd.DataFrame({\n",
    "            'PredictedChurn': preds,\n",
    "            'ChurnProbability': probs\n",
    "        }, index=self.X_test.index)\n",
    "\n",
    "        # map predicted labels back to original (if label encoder used)\n",
    "        if 'Churn' in self.label_encoders:\n",
    "            le = self.label_encoders['Churn']\n",
    "            try:\n",
    "                export_df['PredictedChurnLabel'] = le.inverse_transform(export_df['PredictedChurn'])\n",
    "            except Exception:\n",
    "                export_df['PredictedChurnLabel'] = export_df['PredictedChurn']\n",
    "\n",
    "        # attach customer ID if available from original df\n",
    "        full_df = pd.read_csv(self.data_path)\n",
    "        if self.customer_id_col and self.customer_id_col in full_df.columns:\n",
    "            # align using the original indices — safe because we never shuffled the original df's index during split\n",
    "            id_series = full_df.loc[self.X_test.index, self.customer_id_col] if self.X_test.index.isin(full_df.index).all() else full_df[self.customer_id_col]\n",
    "            export_df.insert(0, self.customer_id_col, id_series.values[:len(export_df)])\n",
    "\n",
    "        export_path = os.path.join(out_dir, \"churn_predictions.csv\")\n",
    "        export_df.to_csv(export_path, index=False)\n",
    "        print(f\"Exported predictions to {export_path}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "def main():\n",
    "    DATA_PATH = \"C:\\\\pro m\\\\ml pro\\\\WA_Fn-UseC_-Telco-Customer-Churn.csv\"  # replace with your actual file if different\n",
    "\n",
    "    predictor = HandcraftedChurnPredictor(DATA_PATH, k_best=20)\n",
    "    (predictor\n",
    "     .load_data()\n",
    "     .feature_engineering()\n",
    "     .encode_and_split()\n",
    "     .handle_class_imbalance()\n",
    "     .feature_selection()\n",
    "     .scale_features()\n",
    "     .train_and_ensemble()\n",
    "     .evaluate_and_report()\n",
    "     .save_artifacts_and_export(out_dir=\"output_handcrafted\"))\n",
    "    print(\"\\n Pipeline finished. Check output_handcrafted/ for artifacts and churn_predictions.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
